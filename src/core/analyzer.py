"""
Module d'analyse IA de vuln√©rabilit√©s - Version NIST avec OpenAI

Ce module analyse les vuln√©rabilit√©s d√©tect√©es par Nmap NSE en utilisant
OpenAI pour fournir des analyses approfondies et des recommandations de rem√©diation.

Workflow NIST:
1. NSE d√©tecte les CVE
2. NIST enrichit avec scores officiels + liens solutions
3. OpenAI explique les solutions en fran√ßais

Fonctionnalit√©s:
- Analyse contextuelle des vuln√©rabilit√©s avec OpenAI
- Calcul de scores de priorit√© et de confiance
- G√©n√©ration de plans de rem√©diation d√©taill√©s
- Cache NIST pour optimisation
- Gestion d'erreurs robuste
"""

import asyncio
import json
import os
import time
import logging
import requests
from pathlib import Path
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple
from dataclasses import dataclass, field, asdict

from openai import AsyncOpenAI, OpenAIError

from config import get_config
from src.utils.logger import setup_logger
from src.core import CoreException, CoreErrorCodes
from src.core.nist_enricher import NISTEnricher

# Configuration du logging
logger = setup_logger(__name__)


# ============================================================================
# EXCEPTIONS PERSONNALIS√âES
# ============================================================================

class AnalyzerException(CoreException):
    """Exception lev√©e par le module Analyzer"""

    def __init__(
            self,
            message: str,
            error_code: int = CoreErrorCodes.AI_SERVICE_ERROR,
            details: Optional[Dict] = None
    ):
        super().__init__(message, error_code, details)


# ============================================================================
# DATACLASSES POUR LES R√âSULTATS
# ============================================================================

@dataclass
class VulnerabilityAnalysis:
    """Analyse d√©taill√©e d'une vuln√©rabilit√© individuelle"""

    vulnerability_id: str
    name: str
    severity: str
    cvss_score: float
    impact_analysis: str
    exploitability: str
    priority_score: int
    affected_service: str
    recommended_actions: List[str]
    dependencies: List[str] = field(default_factory=list)
    references: List[str] = field(default_factory=list)

    # Donn√©es NIST (nouvelles)
    cvss_vector: Optional[str] = None
    nist_verified: bool = False
    nist_url: Optional[str] = None
    solution_links: List[Dict] = field(default_factory=list)

    # Explications IA (nouvelles)
    ai_explanation: Optional[Dict] = None
    correction_script: Optional[str] = None
    rollback_script: Optional[str] = None
    business_impact: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convertit l'analyse en dictionnaire"""
        return asdict(self)


@dataclass
class AnalysisResult:
    """R√©sultat complet de l'analyse"""

    analysis_id: str
    target_system: str
    analyzed_at: datetime
    analysis_summary: Dict[str, Any]
    vulnerabilities: List[VulnerabilityAnalysis]
    remediation_plan: Dict[str, Any]
    ai_model_used: str
    confidence_score: float
    processing_time: float
    business_context: Optional[Dict[str, Any]] = None

    # M√©tadonn√©es NIST (nouvelles)
    nist_enriched: bool = False
    nist_call_count: int = 0
    nist_cache_hits: int = 0

    def to_dict(self) -> Dict[str, Any]:
        """Convertit le r√©sultat en dictionnaire"""
        return {
            "analysis_id": self.analysis_id,
            "target_system": self.target_system,
            "analyzed_at": self.analyzed_at.isoformat(),
            "analysis_summary": self.analysis_summary,
            "vulnerabilities": [v.to_dict() for v in self.vulnerabilities],
            "remediation_plan": self.remediation_plan,
            "ai_model_used": self.ai_model_used,
            "confidence_score": self.confidence_score,
            "processing_time": self.processing_time,
            "business_context": self.business_context,
            "nist_enriched": self.nist_enriched,
            "nist_call_count": self.nist_call_count,
            "nist_cache_hits": self.nist_cache_hits
        }


# ============================================================================
# CACHE NIST
# ============================================================================

class NISTCache:
    """Cache local pour les donn√©es NIST"""

    def __init__(self, cache_dir: str = "data/cache/nist"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.cache_duration = timedelta(hours=24)
        logger.debug(f"Cache NIST initialis√©: {self.cache_dir}")

    def get(self, cve_id: str) -> Optional[Dict]:
        """R√©cup√®re depuis le cache si valide"""
        cache_file = self.cache_dir / f"{cve_id}.json"

        if cache_file.exists():
            file_age = datetime.now() - datetime.fromtimestamp(
                cache_file.stat().st_mtime
            )

            if file_age < self.cache_duration:
                try:
                    with open(cache_file, 'r') as f:
                        return json.load(f)
                except Exception as e:
                    logger.warning(f"Erreur lecture cache {cve_id}: {e}")

        return None

    def set(self, cve_id: str, data: dict):
        """Sauvegarde dans le cache"""
        cache_file = self.cache_dir / f"{cve_id}.json"

        try:
            with open(cache_file, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            logger.warning(f"Erreur √©criture cache {cve_id}: {e}")

    def clear_old(self, max_age_days: int = 7):
        """Nettoie les caches anciens"""
        cutoff = datetime.now() - timedelta(days=max_age_days)
        cleaned = 0

        for cache_file in self.cache_dir.glob("*.json"):
            file_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
            if file_time < cutoff:
                cache_file.unlink()
                cleaned += 1

        if cleaned > 0:
            logger.info(f"Cache NIST nettoy√©: {cleaned} fichiers supprim√©s")


# ============================================================================
# CLASSE PRINCIPALE ANALYZER
# ============================================================================
    def _filter_nist_references(self, references: List[dict]) -> Optional[str]:
        """
        Filtrer les r√©f√©rences NIST pour garder UN SEUL lien solution
        
        Priorit√© : Patch > Vendor Advisory > Mitigation > Premier lien
        """
        if not references:
            return None
        
        # Tags prioritaires (dans l'ordre)
        priority_tags = ['Patch', 'Vendor Advisory', 'Mitigation', 'Third Party Advisory']
        
        # Chercher le premier lien avec un tag prioritaire
        for tag in priority_tags:
            for ref in references:
                ref_tags = ref.get('tags', [])
                if tag in ref_tags:
                    return ref.get('url', '')
        
        # Si aucun tag prioritaire, prendre le premier lien
        return references[0].get('url', '') if references else None
    
    def _enrich_vulnerability_with_nist(self, vulnerability: dict) -> dict:
        """
        Enrichir une vuln√©rabilit√© avec les donn√©es NIST (FILTR√âES)
        """
        cve_id = vulnerability.get('vulnerability_id', '')
        
        if not cve_id or not cve_id.startswith('CVE-'):
            return vulnerability
        
        try:
            # R√©cup√©rer les donn√©es NIST (depuis cache ou API)
            nist_data = self.nist_cache.get(cve_id)
            
            if not nist_data:
                # Appel API NIST (votre code existant)
                # nist_data = self._call_nist_api(cve_id)
                pass
            
            if nist_data:
                # ‚ö° FILTRER pour garder UN SEUL lien
                references = nist_data.get('references', [])
                solution_url = self._filter_nist_references(references)
                
                # Enrichir avec donn√©es essentielles SEULEMENT
                vulnerability['nist_data'] = {
                    'cvss_score': nist_data.get('cvss_score'),
                    'severity': nist_data.get('severity'),
                    'description': nist_data.get('description', '')[:500],  # Limiter
                    'solution_url': solution_url,  # UN SEUL LIEN
                    'published_date': nist_data.get('published_date'),
                    'last_modified': nist_data.get('last_modified')
                }
                
                # NE PAS inclure toutes les r√©f√©rences
                # vulnerability['references'] = references  # ‚Üê SUPPRIM√â
        
        except Exception as e:
            self.logger.warning(f"Erreur enrichissement NIST {cve_id}: {e}")
        
        return vulnerability


class Analyzer:
    """
    Analyseur IA de vuln√©rabilit√©s avec int√©gration NIST et OpenAI

    Workflow:
    1. Re√ßoit les CVE d√©tect√©es par NSE
    2. Enrichit avec NIST (scores officiels + liens solutions)
    3. Fait expliquer les solutions par OpenAI en fran√ßais
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialise l'analyseur

        Args:
            config: Configuration personnalis√©e (optionnelle)
        """
        self.config = config or get_config()
        self.is_ready = False

        # Statistiques
        self.stats = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "average_processing_time": 0.0,
            "nist_api_calls": 0,
            "nist_cache_hits": 0
        }

        # Initialiser les clients IA
        self._init_llm_clients()

        # Initialiser le cache NIST
        self.nist_cache = NISTCache()
        self.nist_api_key = self.config.get('nist_api_key')

        # Nettoyer le vieux cache au d√©marrage
        self.nist_cache.clear_old()

        self.is_ready = True
        logger.info("‚úÖ Analyzer initialis√© (NIST + OpenAI)")

    def _init_llm_clients(self):
        """Initialise le client OpenAI"""
        # Configuration OpenAI uniquement
        api_key = self.config.get('openai_api_key') or os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise AnalyzerException(
                "Cl√© API OpenAI manquante",
                CoreErrorCodes.INVALID_CONFIGURATION
            )

        self.client = AsyncOpenAI(api_key=api_key)
        self.model = self.config.get('openai_model', 'gpt-4')
        logger.info(f"Client OpenAI initialis√© (mod√®le: {self.model})")

    # ========================================================================
    # M√âTHODE BATCH - NOUVELLE
    # ========================================================================

    async def analyze_vulnerabilities_batch(
            self,
            vulnerabilities_data: List[Dict[str, Any]],
            target_system: str = "Unknown System",
            business_context: Optional[Dict[str, Any]] = None,
            batch_size: int = 10
    ) -> AnalysisResult:
        """
        Analyse les vuln√©rabilit√©s par batch pour √©viter les limites OpenAI

        Cette fonction divise les vuln√©rabilit√©s en petits groupes et les analyse
        s√©par√©ment, puis fusionne tous les r√©sultats.

        Args:
            vulnerabilities_data: Liste des CVE d√©tect√©es (peut √™tre tr√®s grande)
            target_system: Nom du syst√®me cible
            business_context: Contexte business optionnel
            batch_size: Nombre de vuln√©rabilit√©s par batch (d√©faut: 10)

        Returns:
            AnalysisResult: R√©sultat complet fusionn√© de tous les batches
        """
        start_time = time.time()
        analysis_id = f"analysis_batch_{int(time.time())}"

        if not self.is_ready:
            raise AnalyzerException(
                "Analyzer non initialis√©",
                CoreErrorCodes.MODULE_NOT_READY
            )

        if not vulnerabilities_data:
            raise AnalyzerException(
                "Liste de vuln√©rabilit√©s vide",
                CoreErrorCodes.INVALID_VULNERABILITY_DATA
            )

        total_vulns = len(vulnerabilities_data)
        logger.info(f"üîç Analyse par batch: {total_vulns} vuln√©rabilit√©s, batch_size={batch_size}")

        # Diviser en batches
        batches = [
            vulnerabilities_data[i:i + batch_size]
            for i in range(0, total_vulns, batch_size)
        ]

        logger.info(f"üì¶ {len(batches)} batches √† traiter")

        # Listes pour fusionner les r√©sultats
        all_vulnerabilities = []
        total_nist_calls = 0
        total_nist_cache_hits = 0

        # Traiter chaque batch
        for i, batch in enumerate(batches, 1):
            logger.info(f"üîÑ Traitement batch {i}/{len(batches)} ({len(batch)} vuln√©rabilit√©s)")

            try:
                # Analyser ce batch avec la fonction normale
                batch_result = await self.analyze_vulnerabilities(
                    vulnerabilities_data=batch,
                    target_system=f"{target_system} (batch {i}/{len(batches)})",
                    business_context=business_context
                )

                # Collecter les r√©sultats
                all_vulnerabilities.extend(batch_result.vulnerabilities)
                total_nist_calls += batch_result.nist_call_count
                total_nist_cache_hits += batch_result.nist_cache_hits

                logger.info(f"‚úÖ Batch {i}/{len(batches)} termin√© ({len(batch_result.vulnerabilities)} vulns)")

                # Pause entre les batches pour √©viter rate limit (2 secondes)
                if i < len(batches):
                    logger.debug(f"‚è∏Ô∏è  Pause 2s avant batch suivant...")
                    await asyncio.sleep(2)

            except Exception as e:
                logger.error(f"‚ùå Erreur batch {i}/{len(batches)}: {e}")
                # Continuer avec les autres batches au lieu de tout arr√™ter
                continue

        # G√©n√©rer le plan de rem√©diation global
        logger.info("üìã G√©n√©ration plan de rem√©diation global...")
        remediation_plan = await self._generate_remediation_plan(
            all_vulnerabilities,
            business_context
        )

        # Calculer les m√©triques globales
        analysis_summary = self._generate_analysis_summary(all_vulnerabilities)
        confidence_score = self._calculate_confidence_score(all_vulnerabilities)

        processing_time = time.time() - start_time

        # Cr√©er le r√©sultat final fusionn√©
        result = AnalysisResult(
            analysis_id=analysis_id,
            target_system=target_system,
            analyzed_at=datetime.utcnow(),
            analysis_summary=analysis_summary,
            vulnerabilities=all_vulnerabilities,
            remediation_plan=remediation_plan,
            ai_model_used=self._get_model_name(),
            confidence_score=confidence_score,
            processing_time=processing_time,
            business_context=business_context,
            nist_enriched=True,  # Toujours true si on a trait√© des batches
            nist_call_count=total_nist_calls,
            nist_cache_hits=total_nist_cache_hits
        )

        # Mettre √† jour les stats
        self._update_stats(success=True, processing_time=processing_time)

        logger.info(f"‚úÖ Analyse batch compl√®te termin√©e en {processing_time:.2f}s")
        logger.info(f"   ‚Ä¢ Total vuln√©rabilit√©s: {len(all_vulnerabilities)}")
        logger.info(f"   ‚Ä¢ Batches trait√©s: {len(batches)}")
        logger.info(f"   ‚Ä¢ NIST calls: {total_nist_calls}")
        logger.info(f"   ‚Ä¢ Cache hits: {total_nist_cache_hits}")

        return result

    # ========================================================================
    # M√âTHODE PRINCIPALE D'ANALYSE - ORIGINALE
    # ========================================================================

    async def analyze_vulnerabilities(
            self,
            vulnerabilities_data: List[Dict[str, Any]],
            target_system: str = "Unknown System",
            business_context: Optional[Dict[str, Any]] = None
    ) -> AnalysisResult:
        """
        Analyse compl√®te des vuln√©rabilit√©s avec workflow NIST

        Args:
            vulnerabilities_data: Liste des CVE d√©tect√©es par NSE
            target_system: Nom du syst√®me cible
            business_context: Contexte business optionnel

        Returns:
            AnalysisResult: R√©sultat complet de l'analyse
        """
        start_time = time.time()
        analysis_id = f"analysis_{int(time.time())}"

        if not self.is_ready:
            raise AnalyzerException(
                "Analyzer non initialis√©",
                CoreErrorCodes.MODULE_NOT_READY
            )

        if not vulnerabilities_data:
            raise AnalyzerException(
                "Liste de vuln√©rabilit√©s vide",
                CoreErrorCodes.INVALID_VULNERABILITY_DATA
            )

        logger.info(f"üîç D√©marrage analyse: {len(vulnerabilities_data)} vuln√©rabilit√©s")

        try:
            # √âTAPE 1 : Enrichir avec NIST
            logger.info("üìä Enrichissement NIST...")
            nist_enricher = NISTEnricher(api_key=self.nist_api_key)

            for vuln in vulnerabilities_data:
                if "cve_id" in vuln:
                    nist_data = await nist_enricher.enrich_cve(vuln["cve_id"])

                    if nist_data:
                        vuln["cvss_score"] = nist_data["cvss_score"]
                        vuln["severity"] = nist_data["severity"]
                        vuln["nist_description"] = nist_data["description"]
                        vuln["solution_links"] = nist_data["solution_links"]
                        vuln["references"] = nist_data["references"]
                        vuln["is_nist_enriched"] = True

                        # Incr√©menter les stats
                        if vuln["cve_id"] in nist_enricher.cache:
                            self.stats["nist_cache_hits"] += 1
                        else:
                            self.stats["nist_api_calls"] += 1
                    else:
                        vuln["is_nist_enriched"] = False

            # √âTAPE 2 : Analyser avec IA
            logger.info("ü§ñ Analyse IA...")
            analyzed_vulns = await self._analyze_with_ai(vulnerabilities_data, business_context)

            # √âTAPE 3 : G√©n√©rer le plan de rem√©diation
            logger.info("üìã G√©n√©ration plan de rem√©diation...")
            remediation_plan = await self._generate_remediation_plan(
                analyzed_vulns,
                business_context
            )

            # √âTAPE 4 : Calculer les m√©triques
            analysis_summary = self._generate_analysis_summary(analyzed_vulns)
            confidence_score = self._calculate_confidence_score(analyzed_vulns)

            processing_time = time.time() - start_time

            # Cr√©er le r√©sultat final
            result = AnalysisResult(
                analysis_id=analysis_id,
                target_system=target_system,
                analyzed_at=datetime.utcnow(),
                analysis_summary=analysis_summary,
                vulnerabilities=analyzed_vulns,
                remediation_plan=remediation_plan,
                ai_model_used=self._get_model_name(),
                confidence_score=confidence_score,
                processing_time=processing_time,
                business_context=business_context,
                nist_enriched=any(v.get("is_nist_enriched", False) for v in vulnerabilities_data),
                nist_call_count=self.stats["nist_api_calls"],
                nist_cache_hits=self.stats["nist_cache_hits"]
            )

            # Mettre √† jour les stats
            self._update_stats(success=True, processing_time=processing_time)

            logger.info(f"‚úÖ Analyse termin√©e en {processing_time:.2f}s")

            return result

        except Exception as e:
            processing_time = time.time() - start_time
            self._update_stats(success=False, processing_time=processing_time)

            logger.error(f"‚ùå Erreur analyse: {e}")
            raise AnalyzerException(
                f"Erreur lors de l'analyse: {str(e)}",
                CoreErrorCodes.AI_SERVICE_ERROR,
                {"original_error": str(e)}
            )

    # ========================================================================
    # PARTIE IA : Analyse avec OpenAI
    # ========================================================================

    async def _analyze_with_ai(
            self,
            vulnerabilities: List[Dict],
            business_context: Optional[Dict]
    ) -> List[VulnerabilityAnalysis]:
        """Analyse les vuln√©rabilit√©s avec OpenAI"""

        # Pr√©parer le prompt
        prompt = self._build_analysis_prompt(vulnerabilities, business_context)

        # Appeler OpenAI
        response = await self._call_openai(prompt)

        # Parser la r√©ponse
        return self._parse_ai_response(response, vulnerabilities)

    async def _call_openai(self, prompt: str) -> str:
        """Appelle OpenAI"""
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000
            )

            return response.choices[0].message.content

        except OpenAIError as e:
            raise AnalyzerException(
                f"Erreur OpenAI: {str(e)}",
                CoreErrorCodes.AI_SERVICE_ERROR
            )

    def _get_system_prompt(self) -> str:
        """Prompt syst√®me pour l'IA"""
        return """Tu es un expert en cybers√©curit√© sp√©cialis√© dans l'analyse de vuln√©rabilit√©s.

üéØ TON R√îLE :
Tu re√ßois des CVE avec leurs scores CVSS et gravit√©s d√©j√† calcul√©s par NIST.
Tu dois analyser l'impact et donner des recommandations.

‚ùå R√àGLES IMPORTANTES :
- Si tu ne connais pas une valeur, utilise 0 pour les nombres, "UNKNOWN" pour les textes
- NE JAMAIS mettre "None" ou null dans les valeurs num√©riques
- Tous les scores doivent √™tre des nombres (0.0 √† 10.0)
- Toutes les gravit√©s doivent √™tre: CRITICAL, HIGH, MEDIUM, LOW, ou UNKNOWN

üìã FORMAT DE R√âPONSE (JSON strict) :
```json
{
  "vulnerabilities": [
    {
      "vulnerability_id": "CVE-XXXX-XXXX",
      "name": "Nom de la vuln√©rabilit√©",
      "severity": "CRITICAL",
      "cvss_score": 9.8,
      "impact_analysis": "Description de l'impact",
      "exploitability": "HIGH",
      "priority_score": 10,
      "affected_service": "Service concern√©",
      "recommended_actions": ["Action 1", "Action 2"],
      "dependencies": [],
      "references": []
    }
  ]
}
```

IMPORTANT : R√©ponds UNIQUEMENT avec ce JSON, sans texte avant ou apr√®s."""

    def _build_analysis_prompt(
            self,
            vulnerabilities: List[Dict],
            business_context: Optional[Dict]
    ) -> str:
        """Construit le prompt d'analyse"""

        prompt = "Analyse ces vuln√©rabilit√©s d√©tect√©es:\n\n"

        for i, vuln in enumerate(vulnerabilities, 1):
            cve_id = vuln.get('cve_id', 'N/A')
            service = vuln.get('service', 'inconnu')
            version = vuln.get('service_version', 'inconnue')
            port = vuln.get('port', 'inconnu')
            cvss = vuln.get('cvss_score', 'N/A')
            severity = vuln.get('severity', 'UNKNOWN')
            nist_verified = vuln.get('is_nist_enriched', False)
            solution_links = vuln.get('solution_links', [])

            prompt += f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Vuln√©rabilit√© #{i}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
CVE : {cve_id}
Service : {service} (version {version})
Port : {port}
Score CVSS : {cvss} {'‚úÖ (NIST officiel)' if nist_verified else '‚ö†Ô∏è (non v√©rifi√©)'}
Gravit√© : {severity} {'‚úÖ (NIST officielle)' if nist_verified else '‚ö†Ô∏è (non v√©rifi√©e)'}
"""

            if vuln.get('nist_description'):
                prompt += f"\nDescription NIST :\n{vuln['nist_description'][:300]}...\n"

            if solution_links:
                prompt += "\nLiens de solutions NIST :\n"
                for link in solution_links:
                    prompt += f"- {link}\n"

            prompt += "\n"

        if business_context:
            prompt += f"\nüìä Contexte business :\n{json.dumps(business_context, indent=2)}\n"

        prompt += """
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
T√ÇCHES :
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Analyse chaque vuln√©rabilit√© et r√©ponds en JSON avec le format sp√©cifi√©.
NE MODIFIE PAS les scores CVSS et gravit√©s fournis par NIST.
"""

        return prompt

    def _parse_ai_response(
            self,
            response: str,
            original_vulns: List[Dict]
    ) -> List[VulnerabilityAnalysis]:
        """Parse la r√©ponse de l'IA"""
        try:
            # Nettoyer la r√©ponse (enlever markdown, etc.)
            cleaned = response.strip()
            if cleaned.startswith("```json"):
                cleaned = cleaned[7:]
            if cleaned.startswith("```"):
                cleaned = cleaned[3:]
            if cleaned.endswith("```"):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()

            # Parser le JSON
            data = json.loads(cleaned)

            # Extraire les vuln√©rabilit√©s
            vulnerabilities = data.get('vulnerabilities', [])

            if not vulnerabilities:
                raise ValueError("Aucune vuln√©rabilit√© dans la r√©ponse IA")

            # Cr√©er les objets VulnerabilityAnalysis
            analyses = []

            for i, vuln_data in enumerate(vulnerabilities):
                # R√©cup√©rer les donn√©es NIST originales
                original = original_vulns[i] if i < len(original_vulns) else {}

                # Cr√©er l'analyse avec gestion robuste des None
                analysis = VulnerabilityAnalysis(
                    vulnerability_id=vuln_data.get('vulnerability_id') or original.get('cve_id') or f'VULN-{i}',
                    name=vuln_data.get('name') or original.get('name') or 'Unknown',
                    severity=vuln_data.get('severity') or original.get('severity') or 'UNKNOWN',
                    cvss_score=float(vuln_data.get('cvss_score') or original.get('cvss_score') or 0.0),
                    impact_analysis=vuln_data.get('impact_analysis') or 'N/A',
                    exploitability=vuln_data.get('exploitability') or 'UNKNOWN',
                    priority_score=int(vuln_data.get('priority_score') or 5),
                    affected_service=vuln_data.get('affected_service') or original.get('service') or 'Unknown',
                    recommended_actions=vuln_data.get('recommended_actions') or [],
                    dependencies=vuln_data.get('dependencies') or [],
                    references=vuln_data.get('references') or original.get('references') or [],

                    # Donn√©es NIST
                    nist_verified=original.get('is_nist_enriched', False),
                    nist_url=f"https://nvd.nist.gov/vuln/detail/{original.get('cve_id', '')}" if original.get(
                        'cve_id') else None,
                    solution_links=original.get('solution_links', []),

                    # Explications IA
                    ai_explanation=vuln_data.get('ai_explanation'),
                    correction_script=vuln_data.get('correction_script'),
                    rollback_script=vuln_data.get('rollback_script'),
                    business_impact=vuln_data.get('business_impact')
                )

                analyses.append(analysis)

            return analyses

        except json.JSONDecodeError as e:
            logger.error(f"Erreur parsing JSON IA: {e}")
            logger.debug(f"R√©ponse brute: {response[:500]}")

            # Fallback: cr√©er des analyses basiques
            return self._create_fallback_analyses(original_vulns)

        except Exception as e:
            logger.error(f"Erreur parsing r√©ponse IA: {e}")
            return self._create_fallback_analyses(original_vulns)

    def _create_fallback_analyses(
            self,
            vulnerabilities: List[Dict]
    ) -> List[VulnerabilityAnalysis]:
        """Cr√©e des analyses basiques si l'IA √©choue"""
        analyses = []

        for vuln in vulnerabilities:
            analysis = VulnerabilityAnalysis(
                vulnerability_id=vuln.get('cve_id', 'UNKNOWN'),
                name=vuln.get('name', 'Unknown Vulnerability'),
                severity=vuln.get('severity', 'UNKNOWN'),
                cvss_score=float(vuln.get('cvss_score') or 0.0),
                impact_analysis="Analyse IA indisponible. Consulter NIST.",
                exploitability="UNKNOWN",
                priority_score=self._calculate_basic_priority(vuln),
                affected_service=vuln.get('service', 'Unknown'),
                recommended_actions=["Consulter la documentation NIST", "Appliquer les patches disponibles"],

                # Donn√©es NIST
                nist_verified=vuln.get('is_nist_enriched', False),
                nist_url=f"https://nvd.nist.gov/vuln/detail/{vuln.get('cve_id', '')}" if vuln.get('cve_id') else None,
                solution_links=vuln.get('solution_links', []),
                references=vuln.get('references', [])
            )

            analyses.append(analysis)

        return analyses

    def _calculate_basic_priority(self, vuln: Dict) -> int:
        """Calcule une priorit√© basique bas√©e sur CVSS"""
        cvss = float(vuln.get('cvss_score') or 0.0)

        if cvss >= 9.0:
            return 10
        elif cvss >= 7.0:
            return 8
        elif cvss >= 4.0:
            return 5
        else:
            return 3

    # ========================================================================
    # G√âN√âRATION DU PLAN DE REM√âDIATION
    # ========================================================================

    async def _generate_remediation_plan(
            self,
            vulnerabilities: List[VulnerabilityAnalysis],
            business_context: Optional[Dict]
    ) -> Dict[str, Any]:
        """G√©n√®re un plan de rem√©diation d√©taill√©"""

        # Trier par priorit√©
        sorted_vulns = sorted(
            vulnerabilities,
            key=lambda v: (v.priority_score, v.cvss_score),
            reverse=True
        )

        # Actions imm√©diates (priorit√© >= 8)
        immediate = [
            {
                "vulnerability_id": v.vulnerability_id,
                "action": v.recommended_actions[0] if v.recommended_actions else "Analyser",
                "priority": v.priority_score,
                "estimated_time": self._estimate_time(v)
            }
            for v in sorted_vulns if v.priority_score >= 8
        ]

        # Actions court terme (5 <= priorit√© < 8)
        short_term = [
            {
                "vulnerability_id": v.vulnerability_id,
                "action": v.recommended_actions[0] if v.recommended_actions else "Planifier",
                "priority": v.priority_score
            }
            for v in sorted_vulns if 5 <= v.priority_score < 8
        ]

        # Actions long terme (priorit√© < 5)
        long_term = [
            {
                "vulnerability_id": v.vulnerability_id,
                "action": "Surveiller et planifier",
                "priority": v.priority_score
            }
            for v in sorted_vulns if v.priority_score < 5
        ]

        # Estimation de dur√©e totale
        total_time = sum(self._estimate_time(v) for v in sorted_vulns)

        return {
            "immediate_actions": immediate,
            "short_term_actions": short_term,
            "long_term_actions": long_term,
            "estimated_total_time_hours": total_time,
            "critical_count": len([v for v in vulnerabilities if v.severity == "CRITICAL"]),
            "high_count": len([v for v in vulnerabilities if v.severity == "HIGH"]),
            "priority_order": [v.vulnerability_id for v in sorted_vulns]
        }

    def _estimate_time(self, vuln: VulnerabilityAnalysis) -> float:
        """Estime le temps de rem√©diation (en heures)"""
        base_time = {
            "CRITICAL": 4.0,
            "HIGH": 2.0,
            "MEDIUM": 1.0,
            "LOW": 0.5
        }

        return base_time.get(vuln.severity, 1.0)

    # ========================================================================
    # M√âTRIQUES ET STATISTIQUES
    # ========================================================================

    def _generate_analysis_summary(
            self,
            vulnerabilities: List[VulnerabilityAnalysis]
    ) -> Dict[str, Any]:
        """G√©n√®re un r√©sum√© de l'analyse"""

        severity_counts = {
            "CRITICAL": 0,
            "HIGH": 0,
            "MEDIUM": 0,
            "LOW": 0,
            "UNKNOWN": 0
        }

        for vuln in vulnerabilities:
            severity_counts[vuln.severity] = severity_counts.get(vuln.severity, 0) + 1

        # Score de risque global (moyenne pond√©r√©e)
        weights = {"CRITICAL": 10, "HIGH": 7, "MEDIUM": 4, "LOW": 2, "UNKNOWN": 0}
        total_weight = sum(weights.get(v.severity, 0) for v in vulnerabilities)
        max_weight = len(vulnerabilities) * 10
        overall_risk = (total_weight / max_weight * 10) if max_weight > 0 else 0

        return {
            "total_vulnerabilities": len(vulnerabilities),
            "critical_count": severity_counts["CRITICAL"],
            "high_count": severity_counts["HIGH"],
            "medium_count": severity_counts["MEDIUM"],
            "low_count": severity_counts["LOW"],
            "unknown_count": severity_counts["UNKNOWN"],
            "overall_risk_score": round(overall_risk, 2),
            "average_cvss": round(
                sum(v.cvss_score for v in vulnerabilities) / len(vulnerabilities), 2
            ) if vulnerabilities else 0.0,
            "highest_priority": max((v.priority_score for v in vulnerabilities), default=0),
            "nist_verified_count": sum(1 for v in vulnerabilities if v.nist_verified)
        }

    def _calculate_confidence_score(
            self,
            vulnerabilities: List[VulnerabilityAnalysis]
    ) -> float:
        """Calcule le score de confiance global"""
        if not vulnerabilities:
            return 0.0

        factors = []

        # Facteur 1: Pourcentage v√©rifi√© par NIST
        nist_verified_pct = sum(1 for v in vulnerabilities if v.nist_verified) / len(vulnerabilities)
        factors.append(nist_verified_pct * 0.4)

        # Facteur 2: Pr√©sence de CVE IDs
        has_cve_pct = sum(
            1 for v in vulnerabilities
            if v.vulnerability_id.startswith('CVE-')
        ) / len(vulnerabilities)
        factors.append(has_cve_pct * 0.3)

        # Facteur 3: Scores CVSS disponibles
        has_cvss_pct = sum(1 for v in vulnerabilities if v.cvss_score > 0) / len(vulnerabilities)
        factors.append(has_cvss_pct * 0.2)

        # Facteur 4: Actions recommand√©es disponibles
        has_actions_pct = sum(
            1 for v in vulnerabilities if v.recommended_actions
        ) / len(vulnerabilities)
        factors.append(has_actions_pct * 0.1)

        return min(1.0, sum(factors))

    # ========================================================================
    # M√âTHODES UTILITAIRES
    # ========================================================================

    def _get_model_name(self) -> str:
        """Retourne le nom du mod√®le OpenAI utilis√©"""
        return self.model

    def _update_stats(self, success: bool, processing_time: float):
        """Met √† jour les statistiques de l'analyseur"""
        self.stats["total_analyses"] += 1

        if success:
            self.stats["successful_analyses"] += 1
        else:
            self.stats["failed_analyses"] += 1

        # Moyenne mobile du temps de traitement
        current_avg = self.stats["average_processing_time"]
        total = self.stats["total_analyses"]
        self.stats["average_processing_time"] = (
                                                        current_avg * (total - 1) + processing_time
                                                ) / total

    def get_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'analyseur"""
        return self.stats.copy()

    def is_healthy(self) -> bool:
        """V√©rifie si l'analyseur est en bonne sant√©"""
        return self.is_ready

    async def close(self):
        """Ferme proprement l'analyseur"""
        logger.info("Fermeture de l'analyzer...")

        # Sauvegarder les stats
        stats_file = Path("data/cache/analyzer_stats.json")
        stats_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            with open(stats_file, 'w') as f:
                json.dump(self.stats, f, indent=2)
            logger.info("Stats sauvegard√©es")
        except Exception as e:
            logger.warning(f"Erreur sauvegarde stats: {e}")

        self.is_ready = False


# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

async def quick_vulnerability_analysis(
        vulnerabilities: List[Dict[str, Any]],
        target_system: str = "Unknown System"
) -> Dict[str, Any]:
    """
    Analyse rapide de vuln√©rabilit√©s (fonction utilitaire)

    Args:
        vulnerabilities: Liste des vuln√©rabilit√©s
        target_system: Syst√®me cible

    Returns:
        Dict contenant l'analyse simplifi√©e
    """
    analyzer = Analyzer()

    try:
        result = await analyzer.analyze_vulnerabilities(
            vulnerabilities,
            target_system
        )
        return result.to_dict()

    except Exception as e:
        logger.error(f"Erreur analyse rapide: {e}")
        return {
            "error": str(e),
            "analysis_summary": {
                "total_vulnerabilities": len(vulnerabilities),
                "overall_risk_score": 0.0
            }
        }
    finally:
        await analyzer.close()


def create_analyzer() -> Analyzer:
    """
    Factory pour cr√©er un analyseur

    Returns:
        Analyzer: Instance configur√©e avec OpenAI
    """
    return Analyzer()


# Alias pour compatibilit√©
VulnerabilityAnalyzer = Analyzer

# ============================================================================
# POINT D'ENTR√âE POUR TESTS
# ============================================================================

if __name__ == "__main__":
    import sys


    async def test_analyzer():
        """Test rapide de l'analyzer"""
        print("üß™ Test de l'Analyzer avec NIST\n")

        # Donn√©es de test
        test_vulns = [
            {
                "cve_id": "CVE-2024-3094",
                "service": "xz-utils",
                "service_version": "5.6.0",
                "port": 22,
                "host": "192.168.1.100"
            }
        ]

        # Cr√©er l'analyzer
        analyzer = Analyzer()

        try:
            print("üìä Analyse en cours...")
            result = await analyzer.analyze_vulnerabilities(
                test_vulns,
                "Test System"
            )

            print("\n‚úÖ Analyse termin√©e!")
            print(f"   ‚Ä¢ Vuln√©rabilit√©s: {result.analysis_summary['total_vulnerabilities']}")
            print(f"   ‚Ä¢ NIST enrichies: {result.nist_enriched}")
            print(f"   ‚Ä¢ Score de risque: {result.analysis_summary['overall_risk_score']}/10")
            print(f"   ‚Ä¢ Temps: {result.processing_time:.2f}s")
            print(f"   ‚Ä¢ Confiance: {result.confidence_score:.2%}")
            print(f"   ‚Ä¢ Appels NIST: {result.nist_call_count}")
            print(f"   ‚Ä¢ Cache hits: {result.nist_cache_hits}")

            # Afficher la premi√®re vuln√©rabilit√©
            if result.vulnerabilities:
                vuln = result.vulnerabilities[0]
                print(f"\nüìã D√©tails {vuln.vulnerability_id}:")
                print(f"   ‚Ä¢ CVSS: {vuln.cvss_score}")
                print(f"   ‚Ä¢ Gravit√©: {vuln.severity}")
                print(f"   ‚Ä¢ NIST v√©rifi√©: {vuln.nist_verified}")
                print(f"   ‚Ä¢ Priorit√©: {vuln.priority_score}/10")
                print(f"   ‚Ä¢ Liens solutions: {len(vuln.solution_links)}")

        except Exception as e:
            print(f"\n‚ùå Erreur: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        finally:
            await analyzer.close()


    # Lancer le test
    asyncio.run(test_analyzer())